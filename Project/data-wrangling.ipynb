{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Data cleaning and manipulation with Pandas\n",
    "\n",
    "**Data set used:** Global sharks attack from kaggle\n",
    "\n",
    "## Question to answer:\n",
    "- Have sharks' location/habitat changed due to climate change/pollution?\n",
    "- Has the month with more attacks changed since 1800? \n",
    "- Has the season with more attacks changed since 1800? \n",
    "\n",
    "To answer this question, I need to check over the time if the attacks' location when they attacked has changed.\n",
    "After some research, it seems that sharks do not live in very cold waters, the usually prefer waters around 22°C, however it depends on the specie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:15.472496Z",
     "start_time": "2020-07-25T00:16:15.467744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install library countryinfo to have more information about the countries:\n",
    "#!pip install countryinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.617330Z",
     "start_time": "2020-07-25T00:16:15.478277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from countryinfo import CountryInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.763004Z",
     "start_time": "2020-07-25T00:16:16.621392Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks = pd.read_csv('../data/attacks.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-19T16:05:46.609306Z",
     "start_time": "2020-07-19T16:05:46.566092Z"
    }
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns: how many there are, if there is any duplicate, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.782799Z",
     "start_time": "2020-07-25T00:16:16.766447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(attacks.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete columns that won't be used: \n",
    "- Investigator or Source\n",
    "- pdf, href, href formula\n",
    "- original order\n",
    "- Name\n",
    "- Sex\n",
    "- Age\n",
    "- Activity\n",
    "- Time\n",
    "- Type\n",
    "- Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.807794Z",
     "start_time": "2020-07-25T00:16:16.789888Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks.drop(columns=['Activity', 'Name', 'Sex ', 'Age', 'Time', 'Type', 'Species ', 'Investigator or Source', \n",
    "                      'pdf', 'href formula', 'href', 'original order'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.838825Z",
     "start_time": "2020-07-25T00:16:16.816685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete last 2 columns because they have no name and one is empty \n",
    "# and in the other one there is only one observation with data\n",
    "\n",
    "attacks.drop(columns=['Unnamed: 23', 'Unnamed: 22'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.900149Z",
     "start_time": "2020-07-25T00:16:16.844487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "attacks = attacks.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.925394Z",
     "start_time": "2020-07-25T00:16:16.908702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all the rows whose case number is 0:\n",
    "attacks = attacks[attacks['Case Number']!= '0']\n",
    "\n",
    "# Remove all the null values:\n",
    "attacks = attacks[~attacks['Case Number'].isnull()]\n",
    "\n",
    "# Remove the last line that contains NaN and the case number is xx:\n",
    "attacks = attacks.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.944513Z",
     "start_time": "2020-07-25T00:16:16.932401Z"
    }
   },
   "outputs": [],
   "source": [
    "# The three columns called Case Number contains the same information, so the last two will be removed:\n",
    "attacks.drop(columns=['Case Number.1', 'Case Number.2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.966903Z",
     "start_time": "2020-07-25T00:16:16.950384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number      0\n",
       "Date             0\n",
       "Year             2\n",
       "Country         50\n",
       "Area           455\n",
       "Location       540\n",
       "Injury          28\n",
       "Fatal (Y/N)    539\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:16.993742Z",
     "start_time": "2020-07-25T00:16:16.974085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018., 2017.,   nan, 2016., 2015., 2014., 2013., 2012., 2011.,\n",
       "       2010., 2009., 2008., 2007., 2006., 2005., 2004., 2003., 2002.,\n",
       "       2001., 2000., 1999., 1998., 1997., 1996., 1995., 1984., 1994.,\n",
       "       1993., 1992., 1991., 1990., 1989., 1969., 1988., 1987., 1986.,\n",
       "       1985., 1983., 1982., 1981., 1980., 1979., 1978., 1977., 1976.,\n",
       "       1975., 1974., 1973., 1972., 1971., 1970., 1968., 1967., 1966.,\n",
       "       1965., 1964., 1963., 1962., 1961., 1960., 1959., 1958., 1957.,\n",
       "       1956., 1955., 1954., 1953., 1952., 1951., 1950., 1949., 1948.,\n",
       "       1848., 1947., 1946., 1945., 1944., 1943., 1942., 1941., 1940.,\n",
       "       1939., 1938., 1937., 1936., 1935., 1934., 1933., 1932., 1931.,\n",
       "       1930., 1929., 1928., 1927., 1926., 1925., 1924., 1923., 1922.,\n",
       "       1921., 1920., 1919., 1918., 1917., 1916., 1915., 1914., 1913.,\n",
       "       1912., 1911., 1910., 1909., 1908., 1907., 1906., 1905., 1904.,\n",
       "       1903., 1902., 1901., 1900., 1899., 1898., 1897., 1896., 1895.,\n",
       "       1894., 1893., 1892., 1891., 1890., 1889., 1888., 1887., 1886.,\n",
       "       1885., 1884., 1883., 1882., 1881., 1880., 1879., 1878., 1877.,\n",
       "       1876., 1875., 1874., 1873., 1872., 1871., 1870., 1869., 1868.,\n",
       "       1867., 1866., 1865., 1864., 1863., 1862., 1861., 1860., 1859.,\n",
       "       1858., 1857., 1856., 1855., 1853., 1852., 1851., 1850., 1849.,\n",
       "       1847., 1846., 1845., 1844., 1842., 1841., 1840., 1839., 1837.,\n",
       "       1836., 1835., 1834., 1832., 1831., 1830., 1829., 1828., 1827.,\n",
       "       1826., 1825., 1823., 1822., 1819., 1818., 1817., 1816., 1815.,\n",
       "       1812., 1811., 1810., 1808., 1807., 1805., 1804., 1803., 1802.,\n",
       "       1801., 1800., 1797., 1792., 1791., 1788., 1787., 1786., 1785.,\n",
       "       1784., 1783., 1780., 1779., 1776., 1771., 1767., 1764., 1758.,\n",
       "       1753., 1751., 1749., 1755., 1748., 1742., 1738., 1733., 1723.,\n",
       "       1721., 1703., 1700., 1642., 1638., 1637., 1617., 1595., 1580.,\n",
       "       1555., 1554., 1543.,  500.,   77.,    5.,    0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what are the unique values of the column Year\n",
    "pd.unique(attacks['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.043116Z",
     "start_time": "2020-07-25T00:16:17.000048Z"
    }
   },
   "outputs": [],
   "source": [
    "# In the rows were the year is 0, some values can be extracted from the date.\n",
    "# I take the last year if there is more than two (i.e. between 2006 - 2009 -> year = 2009)\n",
    "\n",
    "attacks.loc[attacks['Year']== 0,['Year']] = attacks[attacks['Year']== 0]['Date'].str.extract('([\\d]{4}$)').astype('float')\n",
    "\n",
    "# If the null has a year value in Date, extract is and replace it\n",
    "attacks.loc[attacks['Year'].isnull(),'Year'] = attacks[attacks['Year'].isnull()]['Date'].str.extract('([\\d]{4})').astype('float')\n",
    "\n",
    "# Remove all the rows with nulls in the year\n",
    "attacks = attacks[attacks['Year'].notna()]\n",
    "# Years before 1700 AD won't be considered\n",
    "attacks = attacks[attacks['Year'] >= 1700]\n",
    "\n",
    "# Convert to interger all the year column\n",
    "attacks['Year'] = attacks['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean countries' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.066184Z",
     "start_time": "2020-07-25T00:16:17.047852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'MEXICO', 'BRAZIL', 'ENGLAND', 'SOUTH AFRICA',\n",
       "       'THAILAND', 'COSTA RICA', 'MALDIVES', 'BAHAMAS', 'NEW CALEDONIA',\n",
       "       'ECUADOR', 'MALAYSIA', 'LIBYA', nan, 'CUBA', 'MAURITIUS',\n",
       "       'NEW ZEALAND', 'SPAIN', 'SAMOA', 'SOLOMON ISLANDS', 'JAPAN',\n",
       "       'EGYPT', 'ST HELENA, British overseas territory', 'COMOROS',\n",
       "       'REUNION', 'FRENCH POLYNESIA', 'UNITED KINGDOM',\n",
       "       'UNITED ARAB EMIRATES', 'PHILIPPINES', 'INDONESIA', 'CHINA',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'Fiji', 'DOMINICAN REPUBLIC',\n",
       "       'CAYMAN ISLANDS', 'ARUBA', 'MOZAMBIQUE', 'FIJI', 'PUERTO RICO',\n",
       "       'ITALY', 'ATLANTIC OCEAN', 'GREECE', 'ST. MARTIN', 'FRANCE',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'NIGERIA', 'TONGA', 'SCOTLAND',\n",
       "       'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE', 'ANTIGUA', 'KENYA',\n",
       "       'RUSSIA', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)', 'AZORES',\n",
       "       'SOUTH KOREA', 'MALTA', 'VIETNAM', 'MADAGASCAR', 'PANAMA',\n",
       "       'SOMALIA', 'NEVIS', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL',\n",
       "       'YEMEN', 'GULF OF ADEN', 'Sierra Leone', 'ST. MAARTIN',\n",
       "       'GRAND CAYMAN', 'Seychelles', 'LIBERIA', 'VANUATU', 'MEXICO ',\n",
       "       'HONDURAS', 'VENEZUELA', 'SRI LANKA', ' TONGA', 'URUGUAY', 'INDIA',\n",
       "       'MICRONESIA', 'CARIBBEAN SEA', 'OKINAWA', 'TANZANIA',\n",
       "       'MARSHALL ISLANDS', 'EGYPT / ISRAEL', 'NORTHERN ARABIAN SEA',\n",
       "       'HONG KONG', 'EL SALVADOR', 'ANGOLA', 'BERMUDA', 'MONTENEGRO',\n",
       "       'IRAN', 'TUNISIA', 'NAMIBIA', 'NORTH ATLANTIC OCEAN', 'PORTUGAL',\n",
       "       'SOUTH CHINA SEA', 'BANGLADESH', 'PALAU', 'WESTERN SAMOA',\n",
       "       'PACIFIC OCEAN ', 'BRITISH ISLES', 'GRENADA', 'IRAQ', 'TURKEY',\n",
       "       'SINGAPORE', 'NEW BRITAIN', 'SUDAN', 'JOHNSTON ISLAND',\n",
       "       'SOUTH PACIFIC OCEAN', 'NEW GUINEA', 'RED SEA',\n",
       "       'NORTH PACIFIC OCEAN', 'FEDERATED STATES OF MICRONESIA',\n",
       "       'MID ATLANTIC OCEAN', 'ADMIRALTY ISLANDS', 'BRITISH WEST INDIES',\n",
       "       'SOUTH ATLANTIC OCEAN', 'PERSIAN GULF', 'RED SEA / INDIAN OCEAN',\n",
       "       'PACIFIC OCEAN', 'NORTH SEA', 'NICARAGUA ', 'MALDIVE ISLANDS',\n",
       "       'AMERICAN SAMOA', 'ANDAMAN / NICOBAR ISLANDAS', 'GABON', 'MAYOTTE',\n",
       "       'NORTH ATLANTIC OCEAN ', 'THE BALKANS', 'SUDAN?', 'ARGENTINA',\n",
       "       'MARTINIQUE', 'INDIAN OCEAN', 'GUATEMALA', 'NETHERLANDS ANTILLES',\n",
       "       'NORTHERN MARIANA ISLANDS', 'IRAN / IRAQ', 'JAVA', 'SIERRA LEONE',\n",
       "       ' PHILIPPINES', 'NICARAGUA', 'CENTRAL PACIFIC',\n",
       "       'SOLOMON ISLANDS / VANUATU', 'SOUTHWEST PACIFIC OCEAN',\n",
       "       'BAY OF BENGAL', 'MID-PACIFC OCEAN', 'SLOVENIA', 'CURACAO',\n",
       "       'ICELAND', 'ITALY / CROATIA', 'BARBADOS', 'MONACO', 'GUYANA',\n",
       "       'HAITI', 'SAN DOMINGO', 'IRELAND', 'KUWAIT', 'YEMEN ',\n",
       "       'REUNION ISLAND', 'FALKLAND ISLANDS', 'CRETE', 'CYPRUS', 'EGYPT ',\n",
       "       'WEST INDIES', 'BURMA', 'LEBANON', 'PARAGUAY',\n",
       "       'BRITISH NEW GUINEA', 'CEYLON', 'OCEAN', 'GEORGIA', 'SYRIA',\n",
       "       'TUVALU', 'INDIAN OCEAN?', 'GUINEA', 'ANDAMAN ISLANDS',\n",
       "       'EQUATORIAL GUINEA / CAMEROON', 'COOK ISLANDS', 'TOBAGO', 'PERU',\n",
       "       'AFRICA', 'ALGERIA', 'Coast of AFRICA', 'TASMAN SEA', 'GHANA',\n",
       "       'GREENLAND', 'MEDITERRANEAN SEA', 'SWEDEN', 'ROATAN'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(attacks['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all the rows where the columns Country, Area and Location are nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.093485Z",
     "start_time": "2020-07-25T00:16:17.072029Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks.dropna(how='all', subset=['Country','Area','Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.155887Z",
     "start_time": "2020-07-25T00:16:17.099605Z"
    }
   },
   "outputs": [],
   "source": [
    "# The area = English Channel is assigned to England in another entry:\n",
    "\n",
    "attacks.loc[attacks['Area'] == 'English Channel','Country'] = 'UK'\n",
    "\n",
    "attacks.loc[attacks['Location'] == 'Between St. Kitts & Nevis','Country'] = 'Saint Kitts and Nevis'\n",
    "\n",
    "attacks.loc[attacks['Location'] == 'Florida Strait','Country'] = 'Cuba'\n",
    "attacks.loc[attacks['Location'] == 'Between Cuba & Costa Rica','Country'] = 'COSTA RICA'\n",
    "attacks.loc[attacks['Area'] == 'Between Timor & Darwin, Australia','Country'] = 'AUSTRALIA'\n",
    "attacks.loc[attacks['Area'] == 'Near the Andaman & Nicobar Islands','Country'] = 'INDIA'\n",
    "attacks.loc[attacks['Area'] == 'Between Comores & Madagascar','Country'] = 'MADAGASCAR'\n",
    "attacks.loc[attacks['Area'] == '300 miles east of St. Thomas (Virgin Islands)','Country'] = 'MADAGASCAR'\n",
    "\n",
    "attacks = attacks[attacks['Country'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Remove parenthesis and /\n",
    "\n",
    "2) Sustitue all names of the countries for names inside the CountryInfo library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:18:16.223399Z",
     "start_time": "2020-07-25T00:18:16.133439Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks['Country'] = attacks['Country'].str.replace('/ [\\w]+.|\\?','')\n",
    "attacks['Country'] = attacks['Country'].str.replace('^\\s|\\s+$','')\n",
    "attacks['Country'] = attacks['Country'].str.replace('ENGLAND|SCOTLAND|BRITISH VIRGIN ISLANDS','UK')\n",
    "#attacks['Country'] = attacks['Country'].str.replace('BAHAMAS','THE BAHAMAS')\n",
    "attacks['Country'] = attacks['Country'].str.replace('COLUMBIA','COLOMBIA')\n",
    "attacks['Country'] = attacks['Country'].str.replace('OKINAWA','JAPAN')\n",
    "attacks['Country'] = attacks['Country'].str.replace('AZORES','PORTUGAL')\n",
    "attacks['Country'] = attacks['Country'].str.replace('^ATLANTIC OCEAN$','NORTH ATLANTIC OCEAN')\n",
    "attacks['Country'] = attacks['Country'].str.replace('ST. ANGUILLA|CARIBBEAN SEA|ANTIGUA|MARTIN|NEVIS|ST. MAARTIN','ANGUILLA')\n",
    "attacks['Country'] = attacks['Country'].str.replace('GRAND CAYMAN','CAYMAN ISLANDS')\n",
    "attacks['Country'] = attacks['Country'].str.replace('^MICRONESIA','FEDERATED STATES OF MICRONESIA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the null values for country column using the location and area columns and drop the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.336166Z",
     "start_time": "2020-07-25T00:16:17.244455Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks.loc[attacks['Country'].str.contains('UNITED ARAB EMIRATES') ,'Country'] = 'UNITED ARAB EMIRATES'\n",
    "attacks.loc[attacks['Country'].str.contains('RED') ,'Country'] = 'EGYPT' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('ST HELENA') ,'Country'] = 'SAINT HELENA'\n",
    "attacks.loc[attacks['Country'].str.contains('TRINIDAD') ,'Country'] = 'VENEZUELA' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('DIEGO') ,'Country'] = 'MALDIVES' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('PALESTINIAN') ,'Country'] = 'ISRAEL' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('TURK') ,'Country'] = 'HAITI' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('MONTENEGRO') ,'Country'] = 'CROATIA' #chosen for proximity\n",
    "attacks.loc[attacks['Country'].str.contains('GULF OF ADEN') ,'Country'] = 'SOMALIA'\n",
    "attacks.loc[attacks['Country'].str.contains('WESTERN SAMOA') ,'Country'] = 'SAMOA'\n",
    "attacks.loc[attacks['Country'].str.contains('CENTRAL PACIFIC') ,'Country'] = 'SOUTH PACIFIC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the locations called: 'PACIFIC OCEAN', not clear if North or South hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.349360Z",
     "start_time": "2020-07-25T00:16:17.339108Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks = attacks[attacks['Country'] != 'PACIFIC OCEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.378326Z",
     "start_time": "2020-07-25T00:16:17.353772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Case Number, Date, Year, Country, Area, Location, Injury, Fatal (Y/N)]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks[attacks['Country'] == 'CENTRAL PACIFIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a column called Hemisphere and indicate if the attack was in the North or South hemisphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to find out if a country belongs to the North or South hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.392998Z",
     "start_time": "2020-07-25T00:16:17.382960Z"
    }
   },
   "outputs": [],
   "source": [
    "def hemisphere(country):\n",
    "    if 'NORTH' in country or 'SOUTH CHINA SEA' in country:\n",
    "        return 'North'\n",
    "    elif 'SOUTH' in country:\n",
    "        return 'South'\n",
    "    elif CountryInfo(country).latlng()[0] >= 0:\n",
    "        return 'North'\n",
    "    else:\n",
    "        return 'South'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:01.826126Z",
     "start_time": "2020-07-25T00:18:20.931733Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'british isles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-652a0bdc0cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hemisphere'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhemisphere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-61df415cee4b>\u001b[0m in \u001b[0;36mhemisphere\u001b[0;34m(country)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'SOUTH'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'South'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mCountryInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatlng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'North'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/countryinfo/countryinfo.py\u001b[0m in \u001b[0;36mlatlng\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__country_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0m_latlng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__countries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__country_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latlng'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;31m# pprint(_latlng)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'british isles'"
     ]
    }
   ],
   "source": [
    "attacks['Hemisphere'] = attacks['Country'].apply(hemisphere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a month column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:16.937674Z",
     "start_time": "2020-07-25T00:21:16.875840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Así no funciona, creo que es porque crea dos columnas con el resultado. No sé c¿omo hacer que solo haya una columna\n",
    "#attacks['Month'] = attacks['Date'].str.extract('-([\\w]+?)-|(^[a-zA-Z]{3})')\n",
    "\n",
    "attacks['Month'] = attacks['Date'].str.extract('-([\\w]+?)-')\n",
    "\n",
    "# La siguiente línea debería extraer los meses de la columna Date para los valores donde Month es nulo,\n",
    "# pero parece que no hace nada, pero la parte de la derecha sola si que filtra correctamente\n",
    "attacks.loc[attacks['Month'].isnull(), 'Month'] = attacks[attacks['Month'].isnull()]['Date'].str.extract('(^[a-zA-Z]{3})')\n",
    "\n",
    "#Correct July, Ap, March and Sept months' name to 3 letters strings:\n",
    "attacks['Month'] = np.where(attacks['Month']=='July', 'Jul', \n",
    "                            np.where(attacks['Month']=='Ap', 'Apr', \n",
    "                                     np.where(attacks['Month']=='March', 'Mar', \n",
    "                                              np.where(attacks['Month']=='Sept', 'Sep', attacks['Month']))))\n",
    "# Convert months names to numbers\n",
    "look_up = { 'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5,'Jun':6, \n",
    "           'Jul': 7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n",
    "\n",
    "attacks['Month'] = attacks['Month'].apply(lambda x: look_up[x] if x in look_up else x)\n",
    "\n",
    "# Drop nulls values\n",
    "attacks = attacks[attacks['Month'].notna()]\n",
    "\n",
    "# Convert all the values to integers\n",
    "attacks['Month'] = attacks['Month'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some months that in fact they are days, so we need to correct them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:18.103211Z",
     "start_time": "2020-07-25T00:21:18.091146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  4,  3,  2,  1, 12, 11, 10,  9,  8,  7, 30, 26, 24, 17, 13])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(attacks['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:18.523606Z",
     "start_time": "2020-07-25T00:21:18.495763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>1980.12.30</td>\n",
       "      <td>12-30-1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>Eastern Cape Province</td>\n",
       "      <td>Nahoon</td>\n",
       "      <td>No injury, paddleski bitten</td>\n",
       "      <td>N</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>1890.06.26</td>\n",
       "      <td>06-26-1890</td>\n",
       "      <td>1890</td>\n",
       "      <td>CROATIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiume</td>\n",
       "      <td>Legs severed</td>\n",
       "      <td>N</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>1806.04.24</td>\n",
       "      <td>Aug-24-1806</td>\n",
       "      <td>1896</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shark scavenged on the dead sailors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>1803.05.17</td>\n",
       "      <td>May-17-1803</td>\n",
       "      <td>1803</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Off Charleston</td>\n",
       "      <td>No injury</td>\n",
       "      <td>N</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>1802.04.13.R</td>\n",
       "      <td>Reported Apr-13-1802</td>\n",
       "      <td>1802</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number                  Date  Year       Country  \\\n",
       "3048    1980.12.30            12-30-1980  1980  SOUTH AFRICA   \n",
       "5701    1890.06.26            06-26-1890  1890       CROATIA   \n",
       "6125    1806.04.24           Aug-24-1806  1896           USA   \n",
       "6128    1803.05.17           May-17-1803  1803           USA   \n",
       "6130  1802.04.13.R  Reported Apr-13-1802  1802         INDIA   \n",
       "\n",
       "                       Area        Location  \\\n",
       "3048  Eastern Cape Province          Nahoon   \n",
       "5701                    NaN           Fiume   \n",
       "6125                    NaN             NaN   \n",
       "6128         South Carolina  Off Charleston   \n",
       "6130                    NaN             NaN   \n",
       "\n",
       "                                   Injury Fatal (Y/N)  Month  \n",
       "3048          No injury, paddleski bitten           N     30  \n",
       "5701                        Legs severed            N     26  \n",
       "6125  Shark scavenged on the dead sailors         NaN     24  \n",
       "6128                            No injury           N     17  \n",
       "6130                                FATAL           Y     13  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see the month each of these 5 columns should have\n",
    "attacks[attacks['Month'] >12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:19.230562Z",
     "start_time": "2020-07-25T00:21:19.197511Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks.loc[attacks['Month'] == 30,'Month'] = 12\n",
    "attacks.loc[attacks['Month'] == 26,'Month'] = 6\n",
    "attacks.loc[attacks['Month'] == 24,'Month'] = 8\n",
    "attacks.loc[attacks['Month'] == 17,'Month'] = 5\n",
    "attacks.loc[attacks['Month'] == 13,'Month'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a column season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the months for each season and each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:21:21.772768Z",
     "start_time": "2020-07-25T00:21:21.762794Z"
    }
   },
   "outputs": [],
   "source": [
    "n_seasons = {'Winter': [12, 1, 2],\n",
    "             'Spring': [3, 4, 5], \n",
    "             'Summer': [6, 7, 8],\n",
    "             'Autumn': [9, 10, 11]}\n",
    "\n",
    "s_seasons = {'Winter': [6, 7, 8],\n",
    "             'Spring': [9, 10, 11], \n",
    "             'Summer': [12, 1, 2],\n",
    "             'Autumn': [3, 4, 5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the season column and fill it in depending the hemisphere and the month number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:24:57.436033Z",
     "start_time": "2020-07-25T00:24:57.427726Z"
    }
   },
   "outputs": [],
   "source": [
    "def season(var, r):\n",
    "    if var == 'North':\n",
    "        if r in n_seasons['Winter']:\n",
    "            return 'Winter'\n",
    "        elif r in n_seasons['Spring']:\n",
    "            return 'Spring'\n",
    "        elif r in n_seasons['Summer']:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Autumn'\n",
    "    else:\n",
    "        if r in s_seasons['Winter']:\n",
    "            return 'Winter'\n",
    "        elif r in s_seasons['Spring']:\n",
    "            return 'Spring'\n",
    "        elif r in s_seasons['Summer']:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Autumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:24:59.240240Z",
     "start_time": "2020-07-25T00:24:59.171377Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hemisphere'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hemisphere'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5bca331b82b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Season'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hemisphere'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'North'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'North'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Hemisphere'"
     ]
    }
   ],
   "source": [
    "attacks['Season'] = attacks[attacks['Hemisphere']=='North']['Month'].apply(season('North'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the column month next to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.806567Z",
     "start_time": "2020-07-25T00:16:15.578Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:16:17.811166Z",
     "start_time": "2020-07-25T00:16:15.582Z"
    }
   },
   "outputs": [],
   "source": [
    "attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T00:30:08.870874Z",
     "start_time": "2020-07-25T00:30:08.853483Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'values_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-81b165b2ed4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{attr}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         )\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'values_count'"
     ]
    }
   ],
   "source": [
    "attacks.groupby('Month').values_count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
